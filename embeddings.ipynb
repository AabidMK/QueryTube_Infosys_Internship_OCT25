{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b2f6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('master_dataset_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185792cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'description', 'publishedAt', 'tags', 'categoryId',\n",
       "       'defaultLanguage', 'defaultAudioLanguage', 'thumbnail_default',\n",
       "       'thumbnail_high', 'duration', 'viewCount', 'likeCount', 'commentCount',\n",
       "       'privacyStatus', 'channel_id', 'channel_title', 'channel_description',\n",
       "       'channel_country', 'channel_thumbnail', 'channel_subscriberCount',\n",
       "       'channel_videoCount', 'is_transcript_available', 'transcript'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254188f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if text is None or pd.isna(text):\n",
    "        return \"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038c947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why studying bees can teach us about human loneliness sarah kocher tedxnewengland'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"Why studying bees can teach us about human loneliness | Sarah Kocher | TEDxNewEngland\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c9e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_cleaned'] = df['title'].apply(clean_text)\n",
    "df['description_cleaned'] = df['description'].apply(clean_text)\n",
    "df['transcript_cleaned'] = df['transcript'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba1233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    scientists cant explain whats happening on thi...\n",
       "1     million pirate treasure found on the ocean floor\n",
       "2       if you see a rubber band on your door act fast\n",
       "3    cleopatras tomb found egypts greatest discover...\n",
       "4    scientists just solved the mystery of killer w...\n",
       "Name: title_cleaned, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title_cleaned\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797712bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_seconds'] = pd.to_timedelta(df['duration'], errors='coerce').dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d5d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT3H59M26S</td>\n",
       "      <td>14366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT8M50S</td>\n",
       "      <td>530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT4H3M28S</td>\n",
       "      <td>14608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT3H4M25S</td>\n",
       "      <td>11065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT9M14S</td>\n",
       "      <td>554.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     duration  duration_seconds\n",
       "0  PT3H59M26S           14366.0\n",
       "1     PT8M50S             530.0\n",
       "2   PT4H3M28S           14608.0\n",
       "3   PT3H4M25S           11065.0\n",
       "4     PT9M14S             554.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['duration','duration_seconds']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86625f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('master_dataset_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49181e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'description', 'publishedAt', 'tags', 'categoryId',\n",
       "       'defaultLanguage', 'defaultAudioLanguage', 'thumbnail_default',\n",
       "       'thumbnail_high', 'duration', 'viewCount', 'likeCount', 'commentCount',\n",
       "       'privacyStatus', 'channel_id', 'channel_title', 'channel_description',\n",
       "       'channel_country', 'channel_thumbnail', 'channel_subscriberCount',\n",
       "       'channel_videoCount', 'is_transcript_available', 'transcript',\n",
       "       'title_cleaned', 'description_cleaned', 'transcript_cleaned',\n",
       "       'duration_seconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f317f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79e2a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 90.9M/90.9M [00:29<00:00, 3.07MB/s]\n",
      "Downloading model.onnx: 100%|██████████| 90.4M/90.4M [00:27<00:00, 3.32MB/s]\n",
      "Downloading model_O1.onnx: 100%|██████████| 90.4M/90.4M [00:27<00:00, 3.34MB/s]\n",
      "Downloading model_O2.onnx: 100%|██████████| 90.3M/90.3M [00:24<00:00, 3.70MB/s]\n",
      "Downloading model_O3.onnx: 100%|██████████| 90.3M/90.3M [00:25<00:00, 3.59MB/s]\n",
      "Downloading model_O4.onnx: 100%|██████████| 45.2M/45.2M [00:13<00:00, 3.32MB/s]\n",
      "Downloading model_qint8_arm64.onnx: 100%|██████████| 23.0M/23.0M [00:07<00:00, 3.28MB/s]\n",
      "Downloading (…)el_qint8_avx512.onnx: 100%|██████████| 23.0M/23.0M [00:06<00:00, 3.51MB/s]\n",
      "Downloading (…)nt8_avx512_vnni.onnx: 100%|██████████| 23.0M/23.0M [00:06<00:00, 3.54MB/s]\n",
      "Downloading model_quint8_avx2.onnx: 100%|██████████| 23.0M/23.0M [00:05<00:00, 3.89MB/s]\n",
      "Downloading openvino_model.bin: 100%|██████████| 90.3M/90.3M [00:23<00:00, 3.88MB/s]\n",
      "Downloading openvino_model.xml: 211kB [00:00, 68.5MB/s]\n",
      "Downloading (…)_qint8_quantized.bin: 100%|██████████| 22.9M/22.9M [00:05<00:00, 3.86MB/s]\n",
      "Downloading (…)_qint8_quantized.xml: 368kB [00:00, 16.8MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:25<00:00, 3.63MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<?, ?B/s] \n",
      "Downloading tokenizer.json: 466kB [00:00, 4.67MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 350/350 [00:00<?, ?B/s] \n",
      "Downloading train_script.py: 13.2kB [00:00, 4.15MB/s]\n",
      "Downloading vocab.txt: 232kB [00:00, 5.64MB/s]\n",
      "Downloading modules.json: 100%|██████████| 349/349 [00:00<?, ?B/s] \n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Aravapalli Karunya\\AppData\\Local\\Temp\\ipykernel_13492\\3609741328.py\", line 1, in <module>\n",
      "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\", line 95, in __init__\n",
      "    modules = self._load_sbert_model(model_path)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\", line 840, in _load_sbert_model\n",
      "    module = module_class.load(os.path.join(model_path, module_config['path']))\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py\", line 137, in load\n",
      "    return Transformer(model_name_or_path=input_path, **config)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py\", line 29, in __init__\n",
      "    self._load_model(model_name_or_path, config, cache_dir)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py\", line 49, in _load_model\n",
      "    self.auto_model = AutoModel.from_pretrained(model_name_or_path, config=config, cache_dir=cache_dir)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 471, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 2560, in from_pretrained\n",
      "    state_dict = load_state_dict(resolved_archive_file)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 440, in load_state_dict\n",
      "    return safe_load_file(checkpoint_file)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\safetensors\\torch.py\", line 383, in load_file\n",
      "    result[k] = f.get_tensor(k)\n",
      "  File \"d:\\Folders\\INFOSYS\\sentence_fix_env\\Lib\\site-packages\\torch\\storage.py\", line 234, in __getitem__\n",
      "    return super().__getitem__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "027fbeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e=pd.read_csv('master_dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a527f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'description', 'publishedAt', 'tags', 'categoryId',\n",
       "       'defaultLanguage', 'defaultAudioLanguage', 'thumbnail_default',\n",
       "       'thumbnail_high', 'duration', 'viewCount', 'likeCount', 'commentCount',\n",
       "       'privacyStatus', 'channel_id', 'channel_title', 'channel_description',\n",
       "       'channel_country', 'channel_thumbnail', 'channel_subscriberCount',\n",
       "       'channel_videoCount', 'is_transcript_available', 'transcript',\n",
       "       'title_cleaned', 'description_cleaned', 'transcript_cleaned',\n",
       "       'duration_seconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9ea0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(legacy='1.21')\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54da38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e['combined_title_transcript'] = df_e['title_cleaned']+\" \"+df_e['transcript_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c98de75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_tokens=500, overlap=50):\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return []\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = start + max_tokens\n",
    "        chunk = ' '.join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap\n",
    "        if start >= len(words):\n",
    "            break\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6235a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_pytorch(text):\n",
    "    \"\"\"Use pure PyTorch to avoid numpy issues\"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return torch.zeros(384, dtype=torch.float32)\n",
    "    \n",
    "    chunks = chunk_text(text)\n",
    "    if not chunks:\n",
    "        return torch.zeros(384, dtype=torch.float32)\n",
    "    \n",
    "    try:\n",
    "        # Get embeddings as tensor\n",
    "        chunk_embeddings = model.encode(chunks, convert_to_tensor=True)\n",
    "        \n",
    "        # Calculate mean using PyTorch\n",
    "        if len(chunk_embeddings.shape) > 1:\n",
    "            final_embedding = chunk_embeddings.mean(dim=0)\n",
    "        else:\n",
    "            final_embedding = chunk_embeddings\n",
    "            \n",
    "        return final_embedding.cpu()  # Ensure it's on CPU\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return torch.zeros(384, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd7d88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e['e_title_trans_tensor'] = df_e['combined_title_transcript'].apply(get_embeddings_pytorch)\n",
    "df_e['e_description_tensor'] = df_e['description_cleaned'].apply(get_embeddings_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d181f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'description', 'publishedAt', 'tags', 'categoryId',\n",
       "       'defaultLanguage', 'defaultAudioLanguage', 'thumbnail_default',\n",
       "       'thumbnail_high', 'duration', 'viewCount', 'likeCount', 'commentCount',\n",
       "       'privacyStatus', 'channel_id', 'channel_title', 'channel_description',\n",
       "       'channel_country', 'channel_thumbnail', 'channel_subscriberCount',\n",
       "       'channel_videoCount', 'is_transcript_available', 'transcript',\n",
       "       'title_cleaned', 'description_cleaned', 'transcript_cleaned',\n",
       "       'duration_seconds', 'combined_title_transcript', 'e_title_trans_tensor',\n",
       "       'e_description_tensor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e46b164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e.to_csv('master_dataset_embedded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5648072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentence_fix_env (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
